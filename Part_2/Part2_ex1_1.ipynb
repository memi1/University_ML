{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1\n",
    "-  изчислете \"на ръка\" и чрез PyTorch стойностите на невроните $z_i^{(j)}$, като и стойностите на производните $∂_{w_{11}^{(2)}}L,∂_{w_{21}^{(2)}}L,∂_{w_{11}^{(1)}}L$;\n",
    "- обновете чрез PyTorch един път стойностите на величините по мрежата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('lin1', nn.Linear(3, 2)),\n",
    "    ('sig1', nn.Sigmoid()),\n",
    "    ('lin2', nn.Linear(2, 2)),\n",
    "    ('sig2', nn.Sigmoid())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lin1.weight.data = torch.tensor(np.array([0.1,0.3,0.25,0.2,0.15,0.11]).reshape((2, 3))).float()\n",
    "model.lin1.bias.data = torch.zeros_like(model.lin1.bias.data).float()\n",
    "model.lin2.weight.data = torch.tensor(np.array([0.3,0.1,0.2,0.2]).reshape((2, 2))).float()\n",
    "model.lin2.bias.data = torch.zeros_like(model.lin2.bias.data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0.3, 0.1, 0.5])\n",
    "a1 = model.lin1(x)\n",
    "z1 = model.sig1(a1)\n",
    "y = model(x)\n",
    "t = torch.tensor([0.5,0.55]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values:  tensor([0.3000, 0.1000, 0.5000])\n",
      "First layer:  tensor([0.5461, 0.5325], grad_fn=<SigmoidBackward0>)\n",
      "Output layer:  tensor([0.5541, 0.5537], grad_fn=<SigmoidBackward0>)\n",
      "Target values:  tensor([0.5000, 0.5500])\n"
     ]
    }
   ],
   "source": [
    "print('Input values: ', x)\n",
    "print('First layer: ', z1)\n",
    "print('Output layer: ', y)\n",
    "print('Target values: ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "L = loss(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1164e-04, 1.0388e-04, 5.1940e-04],\n",
      "        [1.1348e-04, 3.7828e-05, 1.8914e-04]])\n",
      "tensor([[0.0073, 0.0071],\n",
      "        [0.0005, 0.0005]])\n"
     ]
    }
   ],
   "source": [
    "print(model.lin1.weight.grad)\n",
    "print(model.lin2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1000, 0.3000, 0.2500],\n",
      "        [0.2000, 0.1500, 0.1100]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.3000, 0.1000],\n",
      "        [0.2000, 0.2000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.lin1.weight)\n",
    "print(model.lin2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1000, 0.3000, 0.2500],\n",
      "        [0.2000, 0.1500, 0.1100]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.2999, 0.0999],\n",
      "        [0.2000, 0.2000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.lin1.weight)\n",
    "print(model.lin2.weight)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
